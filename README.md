# ğŸµ A Deep Learning Framework for Emotion Recognition in Music Using Multimodal Data Fusion

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-orange.svg)](https://tensorflow.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-in%20development-yellow.svg)](ROADMAP.md)

**SyncIn** is an advanced **multimodal emotion recognition framework** that combines Computer Vision, Audio Processing, Natural Language Processing, and Music Information Retrieval to create an intelligent, emotion-aware music recommendation system.

## ğŸ”¬ Research Focus

This project implements a **deep learning framework** that:
- ğŸ­ Detects user emotions from **multiple modalities** (facial expressions, voice, text, biosignals)
- ğŸµ Analyzes emotions **within music tracks** using audio features and lyrics
- ğŸ§  Employs **attention-based multimodal fusion** for accurate emotion prediction
- ğŸ¯ Recommends music using **context-aware deep learning** techniques

> **Current Version (v1.0):** Facial emotion recognition âœ…  
> **Roadmap:** See [ROADMAP.md](ROADMAP.md) for complete multimodal implementation plan

## ğŸ¯ Features

### Current (v1.0)
- âœ… **Real-time Facial Emotion Detection**: Webcam-based facial expression analysis
- âœ… **AI-Powered Recognition**: TensorFlow CNN for emotion classification
- âœ… **Automatic Music Selection**: Mood-based song recommendations
- âœ… **Three Emotion Categories**: Angry, Happy, and Neutral/Sad
- âœ… **Interactive Music Controls**: Full playback control with GUI
- âœ… **Error Handling**: Robust audio file processing
- âœ… **Cross-Platform**: macOS, Linux, and Windows support

### Upcoming (v2.0 - Multimodal) ğŸš€
- ğŸ”„ **Audio Emotion Recognition**: Voice/speech emotion detection
- ğŸ”„ **Text Sentiment Analysis**: NLP-based emotion from text input
- ğŸ”„ **Music Emotion Recognition**: Analyze emotions IN music tracks
- ğŸ”„ **Attention-Based Fusion**: Deep learning multimodal integration
- ğŸ”„ **Biosignal Integration**: Heart rate & GSR emotion detection (optional)
- ğŸ”„ **Context Awareness**: Temporal and environmental context
- ğŸ”„ **Advanced Recommendations**: Mood regulation & enhancement strategies
- ğŸ”„ **Professional Dashboard**: Real-time multimodal visualization

ğŸ“‹ **See [TODO.md](TODO.md) for detailed implementation checklist**

## ğŸš€ Quick Start

### Prerequisites

- Python 3.13 or higher
- Webcam
- macOS, Linux, or Windows

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/bhargav59/SyncIn-Emotion-Music-Player.git
   cd SyncIn-Emotion-Music-Player
   ```

2. **Create and activate virtual environment**

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On macOS/Linux
   # OR
   .venv\Scripts\activate     # On Windows
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

### Running the Application

```bash
python label.py
```

The application will:

1. Open your webcam in a window titled "Capture"
2. Detect your face and analyze your emotion (collects 10 predictions)
3. Determine your predominant mood
4. Open a "Music Player Controls" window and start playing music

## ğŸ® Controls

### Webcam Window

- **ESC** - Exit the application

### Music Player Controls Window

- **P** - Pause music
- **R** - Resume music
- **S** - Stop current song
- **E** or **Q** - Exit player

## ğŸ“š Libraries & Technologies

| Library          | Version | Purpose                                 |
| ---------------- | ------- | --------------------------------------- |
| **OpenCV (cv2)** | Latest  | Face detection and webcam capture       |
| **TensorFlow**   | 2.20+   | Deep learning emotion recognition model |
| **NumPy**        | Latest  | Numerical operations and array handling |
| **Pandas**       | Latest  | Reading and managing song playlists     |
| **Pygame**       | Latest  | Audio playback and UI controls          |

## ğŸ”„ How It Works

### System Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Webcam Capture â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Face Detection  â”‚ (OpenCV Haar Cascade)
â”‚ haarcascade_    â”‚
â”‚ frontalface_    â”‚
â”‚ alt.xml         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Emotion         â”‚ (TensorFlow Model)
â”‚ Recognition     â”‚ retrained_graph.pb
â”‚ (label_image.py)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collect 10      â”‚
â”‚ Predictions     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Determine Most  â”‚
â”‚ Common Emotion  â”‚
â”‚ (Angry/Happy/   â”‚
â”‚  Neutral-Sad)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Song from  â”‚
â”‚ emotions_file/  â”‚
â”‚ [emotion].csv   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Play Music      â”‚ (Pygame)
â”‚ from songs/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Process

1. **Face Detection (`label.py`)**

   - Captures video from webcam using OpenCV
   - Detects faces using Haar Cascade classifier
   - Extracts face region and saves as `test.jpg`

2. **Emotion Recognition (`label_image.py`)**

   - Loads pre-trained TensorFlow model (`retrained_graph.pb`)
   - Processes face image through neural network
   - Returns emotion classification (1=Angry, 2=Happy, 3=Neutral/Sad)

3. **Prediction Collection**

   - Collects 10 emotion predictions for accuracy
   - Calculates most frequent emotion detected

4. **Music Selection (`play_music_pygame.py`)**
   - Reads corresponding CSV file from `emotions_file/`
   - Randomly selects a song from the playlist
   - Loads and plays the MP3 file using Pygame

## ğŸ“ Project Structure

```
SyncIn-Emotion-Music-Player/
â”œâ”€â”€ label.py                              # Main application entry point
â”œâ”€â”€ label_image.py                        # TensorFlow emotion recognition
â”œâ”€â”€ play_music_pygame.py                  # Music player with controls
â”œâ”€â”€ face_crop.py                          # Face cropping utility
â”œâ”€â”€ retrain.py                            # Model training script
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”œâ”€â”€ retrained_graph.pb                    # Pre-trained TensorFlow model
â”œâ”€â”€ retrained_labels.txt                  # Emotion labels mapping
â”œâ”€â”€ haarcascade_frontalface_alt.xml       # Face detection cascade
â”œâ”€â”€ emotions_file/                        # Emotion-based playlists
â”‚   â”œâ”€â”€ Angry.csv
â”‚   â”œâ”€â”€ Happy.csv
â”‚   â””â”€â”€ NeutralOrSad.csv
â”œâ”€â”€ songs/                                # Music library (MP3 files)
â””â”€â”€ images/                               # Training dataset
    â”œâ”€â”€ angry/
    â”œâ”€â”€ happy/
    â””â”€â”€ neutral or sad/
```

## ğŸ“ Training Your Own Model

If you want to train a custom emotion recognition model:

1. Add training images to the `images/` folders (angry, happy, neutral or sad)
2. Follow instructions in `how to train.txt`
3. Run `retrain.py` to generate a new `retrained_graph.pb` model
4. The new model will be used automatically

## ğŸµ Adding Your Own Songs

1. Add MP3 files to the `songs/` folder
2. Update the corresponding CSV file in `emotions_file/`:
   - `Angry.csv` for angry mood songs
   - `Happy.csv` for happy mood songs
   - `NeutralOrSad.csv` for calm/sad mood songs
3. Add song names (without .mp3 extension) to the CSV

## ğŸ› Troubleshooting

### Webcam not working

- Check if another application is using the webcam
- Grant camera permissions to Terminal/Python

### TensorFlow warnings

- These are normal compatibility warnings and don't affect functionality

### Corrupted MP3 file error

- The app will automatically skip corrupted files
- Remove or replace the corrupted MP3 from the songs folder

### Permission denied on macOS

- Run: `chmod +x label.py`
- Grant necessary permissions in System Preferences â†’ Security & Privacy

## ğŸ”§ Technical Improvements (v2.0)

- âœ… Updated for TensorFlow 2.x compatibility
- âœ… Replaced keyboard library with Pygame event handling
- âœ… Added error handling for corrupted audio files
- âœ… macOS compatibility fixes (replaced `cls` with `clear`)
- âœ… Improved music player controls with GUI window
- âœ… Added virtual environment support
- âœ… Created comprehensive requirements.txt

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ‘¨â€ğŸ’» Author

**Bhargav Sah**

- GitHub: [@bhargav59](https://github.com/bhargav59)
- Portfolio: [bhargav59.github.io/Portfolio](https://bhargav59.github.io/Portfolio/)

## ğŸ™ Acknowledgments

- Original concept by [mmudit30](https://github.com/mmudit30/SyncIn)
- TensorFlow team for the deep learning framework
- OpenCV community for computer vision tools
- Pygame community for audio playback capabilities

---

â­ If you found this project helpful, please give it a star!
